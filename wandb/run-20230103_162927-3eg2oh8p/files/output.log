Loading hyperparameters from: .\hyperparams\tqc.yml
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('env_wrapper', 'stable_baselines3.common.monitor.Monitor'),
             ('learning_rate', 0.001),
             ('n_timesteps', 20000),
             ('policy', 'MlpPolicy')])
Using 1 environments
Creating test environment
Using cpu device
Log path: logs/tqc/TestEnvironment-v1_24
Logging to runs/TestEnvironment-v1__tqc__2732247234__1672759765\TestEnvironment-v1\TQC_1
Eval num_timesteps=200, episode_reward=7.35 +/- 5.80
Episode length: 200.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 200      |
|    mean_reward     | 7.35     |
| time/              |          |
|    total_timesteps | 200      |
| train/             |          |
|    actor_loss      | -2.76    |
|    critic_loss     | 0.00825  |
|    ent_coef        | 0.907    |
|    ent_coef_loss   | -0.328   |
|    learning_rate   | 0.001    |
|    n_updates       | 99       |
---------------------------------
New best mean reward!



Eval num_timesteps=400, episode_reward=6.64 +/- 5.60
Episode length: 200.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 200      |
|    mean_reward     | 6.64     |
| time/              |          |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | -3.2     |
|    critic_loss     | 0.00613  |
|    ent_coef        | 0.742    |
|    ent_coef_loss   | -1       |
|    learning_rate   | 0.001    |
|    n_updates       | 299      |
---------------------------------



Eval num_timesteps=600, episode_reward=6.73 +/- 6.70
Episode length: 200.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 200      |
|    mean_reward     | 6.73     |
| time/              |          |
|    total_timesteps | 600      |
| train/             |          |
|    actor_loss      | -3.66    |
|    critic_loss     | 0.00865  |
|    ent_coef        | 0.608    |
|    ent_coef_loss   | -1.68    |
|    learning_rate   | 0.001    |
|    n_updates       | 499      |
---------------------------------


Eval num_timesteps=800, episode_reward=6.87 +/- 6.45
Episode length: 200.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 200      |
|    mean_reward     | 6.87     |
| time/              |          |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | -3.97    |
|    critic_loss     | 0.00547  |
|    ent_coef        | 0.497    |
|    ent_coef_loss   | -2.36    |
|    learning_rate   | 0.001    |
|    n_updates       | 699      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 200      |
|    ep_rew_mean     | 9.98     |
| time/              |          |
|    episodes        | 4        |
|    fps             | 30       |
|    time_elapsed    | 26       |
|    total_timesteps | 800      |
---------------------------------



Eval num_timesteps=1000, episode_reward=2.92 +/- 2.61
Episode length: 200.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 200      |
|    mean_reward     | 2.92     |
| time/              |          |
|    total_timesteps | 1000     |
| train/             |          |
|    actor_loss      | -4.24    |
|    critic_loss     | 0.00729  |
|    ent_coef        | 0.407    |
|    ent_coef_loss   | -3.03    |
|    learning_rate   | 0.001    |
|    n_updates       | 899      |
---------------------------------
[35m   5%[39m [38m━━━━━━━━━╸━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [32m1,080/20,000 [39m [ [33m0:00:35[39m < [36m0:11:57[39m , [31m26 it/s[39m ]
[35m   6%[39m [38m━━━━━━━━━━╺━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [32m1,148/20,000 [39m [ [33m0:00:37[39m < [36m0:11:42[39m , [31m27 it/s[39m ]
[35m   6%[39m [38m━━━━━━━━━━╸━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [32m1,199/20,000 [39m [ [33m0:00:40[39m < [36m0:11:36[39m , [31m27 it/s[39m ]
|    ent_coef_loss   | -3.69    |reward=7.52 +/- 6.71
|    critic_loss     | 0.00494  |
|    ent_coef        | 0.333    |
|    ent_coef_loss   | -3.69    |reward=7.52 +/- 6.71
|    learning_rate   | 0.001    |
|    n_updates       | 1099     |
---------------------------------
New best mean reward!
[35m   7%[39m [38m━━━━━━━━━━━╸━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [32m1,320/20,000 [39m [ [33m0:00:44[39m < [36m0:11:10[39m , [31m28 it/s[39m ]
[35m   7%[39m [38m━━━━━━━━━━━━╺━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [32m1,368/20,000 [39m [ [33m0:00:46[39m < [36m0:11:11[39m , [31m28 it/s[39m ]
New best mean reward!
[35m   7%[39m [38m━━━━━━━━━━━━╸━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [32m1,404/20,000 [39m [ [33m0:00:48[39m < [36m0:11:21[39m , [31m27 it/s[39m ]
New best mean reward!
New best mean reward!
New best mean reward!
|    time_elapsed    | 55       |
|    time_elapsed    | 55       |
|    time_elapsed    | 55       |
|    time_elapsed    | 55       |
|    learning_rate   | 0.001    |
|    learning_rate   | 0.001    |
|    learning_rate   | 0.001    |
|    learning_rate   | 0.001    |
|    learning_rate   | 0.001    |
|    learning_rate   | 0.001    |
|    learning_rate   | 0.001    |
|    learning_rate   | 0.001    |
|    learning_rate   | 0.001    |
|    learning_rate   | 0.001    |
|    learning_rate   | 0.001    |
|    episodes        | 12       |
|    episodes        | 12       |
|    episodes        | 12       |
|    ent_coef        | 0.0823   |
|    ent_coef        | 0.0823   |
|    ent_coef        | 0.0823   |
|    ent_coef        | 0.0673   |
|    ent_coef        | 0.0673   |
|    ent_coef        | 0.0673   |
|    ent_coef        | 0.0673   |
|    ent_coef        | 0.0551   |
|    ent_coef        | 0.0551   |
|    ent_coef        | 0.0551   |
|    ent_coef        | 0.0551   |
|    ent_coef        | 0.0551   |
[35m  16%[39m [38m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [32m3,256/20,000 [39m [ [33m0:01:56[39m < [36m0:10:24[39m , [31m27 it/s[39m ]
[35m  17%[39m [38m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [32m3,318/20,000 [39m [ [33m0:01:58[39m < [36m0:10:26[39m , [31m27 it/s[39m ]
[35m  17%[39m [38m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [32m3,375/20,000 [39m [ [33m0:02:00[39m < [36m0:10:29[39m , [31m26 it/s[39m ]
[35m  17%[39m [38m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [32m3,400/20,000 [39m [ [33m0:02:01[39m < [36m0:10:18[39m , [31m27 it/s[39m ]
[35m  22%
|    actor_loss      | -4.9     |
|    critic_loss     | 0.000187 |
|    ent_coef        | 0.0136   |
|    ent_coef_loss   | -14.5    |
|    learning_rate   | 0.001    |
|    n_updates       | 4299     |
---------------------------------
[35m  23%[39m [38m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [32m4,599/20,000 [39m [ [33m0:02:47[39m < [36m0:09:27[39m , [31m27 it/s[39m ]
[35m  23%[39m [38m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [32m4,652/20,000 [39m [ [33m0:02:49[39m < [36m0:09:35[39m , [31m27 it/s[39m ]
|    actor_loss      | -4.77    |
|    critic_loss     | 0.000245 |
|    ent_coef        | 0.0111   |
|    ent_coef_loss   | -15.2    |
|    learning_rate   | 0.001    |
|    n_updates       | 4499     |
---------------------------------
[35m  24%[39m [38m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [32m4,713/20,000 [39m [ [33m0:02:51[39m < [36m0:09:28[39m , [31m27 it/s[39m ]
[35m  24%[39m [38m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [32m4,772/20,000 [39m [ [33m0:02:53[39m < [36m0:09:25[39m , [31m27 it/s[39m ]
|    total_timesteps | 4800     |
| rollout/           |          |
|    ep_len_mean     | 200      |
|    ep_rew_mean     | 6.21     |
| time/              |          |
|    episodes        | 24       |
|    fps             | 27       |
|    time_elapsed    | 174      |
|    total_timesteps | 4800     |
---------------------------------
[35m  24%[39m [38m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [32m4,869/20,000 [39m [ [33m0:02:57[39m < [36m0:09:28[39m , [31m27 it/s[39m ]
[35m  25%[39m [38m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [32m4,927/20,000 [39m [ [33m0:02:59[39m < [36m0:09:29[39m , [31m27 it/s[39m ]
[35m  25%[39m [38m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [32m4,991/20,000 [39m [ [33m0:03:01[39m < [36m0:09:27[39m , [31m27 it/s[39m ]
|    critic_loss     | 0.00015  |reward=3.33 +/- 3.51
|    critic_loss     | 0.00015  |reward=3.33 +/- 3.51
|    critic_loss     | 0.00015  |reward=3.33 +/- 3.51
|    n_updates       | 5099     |reward=3.33 +/- 3.51
|    n_updates       | 5099     |reward=3.33 +/- 3.51
|    n_updates       | 5099     |reward=3.33 +/- 3.51
|    n_updates       | 5099     |reward=3.33 +/- 3.51
| train/             |          |reward=3.33 +/- 3.51
| train/             |          |reward=3.33 +/- 3.51
| train/             |          |reward=3.33 +/- 3.51
| train/             |          |reward=3.33 +/- 3.51
|    fps             | 27       |
|    fps             | 27       |
|    fps             | 27       |
|    fps             | 27       |
|    actor_loss      | -4.6     |
|    actor_loss      | -4.6     |
|    actor_loss      | -4.6     |
|    actor_loss      | -4.6     |
|    actor_loss      | -4.25    |
|    actor_loss      | -4.25    |
|    actor_loss      | -4.25    |
|    actor_loss      | -4.44    |
|    actor_loss      | -4.44    |
|    actor_loss      | -4.44    |
|    actor_loss      | -4.44    |
|    ep_rew_mean     | 5.81     |
|    ep_rew_mean     | 5.81     |
|    ep_rew_mean     | 5.81     |
|    actor_loss      | -4.46    |
|    actor_loss      | -4.46    |
|    actor_loss      | -4.46    |