Loading hyperparameters from: .\hyperparams\tqc.yml
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('env_wrapper', 'stable_baselines3.common.monitor.Monitor'),
             ('learning_rate', 0.001),
             ('n_timesteps', 20000),
             ('policy', 'MlpPolicy')])
Using 1 environments
Creating test environment
Using cpu device
Log path: logs/tqc/TestEnvironment-v1_27
Logging to runs/TestEnvironment-v1__tqc__2697349292__1672760324\TestEnvironment-v1\TQC_1
Eval num_timesteps=200, episode_reward=3.03 +/- 3.26
Episode length: 200.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 200      |
|    mean_reward     | 3.03     |
| time/              |          |
|    total_timesteps | 200      |
| train/             |          |
|    actor_loss      | -2.78    |
|    critic_loss     | 0.00878  |
|    ent_coef        | 0.907    |
|    ent_coef_loss   | -0.329   |
|    learning_rate   | 0.001    |
|    n_updates       | 99       |
---------------------------------
New best mean reward!


Eval num_timesteps=400, episode_reward=4.63 +/- 4.88
Episode length: 200.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 200      |
|    mean_reward     | 4.63     |
| time/              |          |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | -3.14    |
|    critic_loss     | 0.00843  |
|    ent_coef        | 0.742    |
|    ent_coef_loss   | -1       |
|    learning_rate   | 0.001    |
|    n_updates       | 299      |
---------------------------------
New best mean reward!


Eval num_timesteps=600, episode_reward=5.17 +/- 5.53
Episode length: 200.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 200      |
|    mean_reward     | 5.17     |
| time/              |          |
|    total_timesteps | 600      |
| train/             |          |
|    actor_loss      | -3.5     |
|    critic_loss     | 0.0102   |
|    ent_coef        | 0.608    |
|    ent_coef_loss   | -1.67    |
|    learning_rate   | 0.001    |
|    n_updates       | 499      |
---------------------------------
New best mean reward!


Eval num_timesteps=800, episode_reward=2.32 +/- 3.01
Episode length: 200.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 200      |
|    mean_reward     | 2.32     |
| time/              |          |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | -3.85    |
|    critic_loss     | 0.00481  |
|    ent_coef        | 0.497    |
|    ent_coef_loss   | -2.37    |
|    learning_rate   | 0.001    |
|    n_updates       | 699      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 200      |
|    ep_rew_mean     | 2.87     |
| time/              |          |
|    episodes        | 4        |
|    fps             | 36       |
|    time_elapsed    | 21       |
|    total_timesteps | 800      |
---------------------------------


Eval num_timesteps=1000, episode_reward=8.88 +/- 7.41
Episode length: 200.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 200      |
|    mean_reward     | 8.88     |
| time/              |          |
|    total_timesteps | 1000     |
| train/             |          |
|    actor_loss      | -4.09    |
|    critic_loss     | 0.00539  |
|    ent_coef        | 0.407    |
|    ent_coef_loss   | -3.01    |
|    learning_rate   | 0.001    |
|    n_updates       | 899      |
---------------------------------
New best mean reward!
[35m   5%[39m [38m━━━━━━━━━╸━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [32m1,074/20,000 [39m [ [33m0:00:30[39m < [36m0:09:56[39m , [31m32 it/s[39m ]
[35m   6%[39m [38m━━━━━━━━━━╺━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [32m1,120/20,000 [39m [ [33m0:00:31[39m < [36m0:09:55[39m , [31m32 it/s[39m ]
[35m   6%[39m [38m━━━━━━━━━━╸━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [32m1,196/20,000 [39m [ [33m0:00:33[39m < [36m0:09:39[39m , [31m33 it/s[39m ]
|    ent_coef_loss   | -3.69    |reward=5.36 +/- 7.12
|    ent_coef_loss   | -3.69    |reward=5.36 +/- 7.12
|    ent_coef_loss   | -3.69    |reward=5.36 +/- 7.12
|    n_updates       | 1299     |
|    n_updates       | 1299     |
|    n_updates       | 1299     |
|    fps             | 34       |
|    time_elapsed    | 46       |
|    total_timesteps | 1600     |
---------------------------------
[35m   8%[39m [38m━━━━━━━━━━━━━━╸━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [32m1,641/20,000 [39m [ [33m0:00:48[39m < [36m0:09:44[39m , [31m31 it/s[39m ]
|    fps             | 34       |
|    fps             | 34       |
|    n_updates       | 1699     |
---------------------------------
[35m   9%[39m [38m━━━━━━━━━━━━━━━━╺━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [32m1,810/20,000 [39m [ [33m0:00:54[39m < [36m0:09:55[39m , [31m31 it/s[39m ]
|    n_updates       | 1699     |
|    n_updates       | 1699     |
|    n_updates       | 1699     |
[35m  10%[39m [38m━━━━━━━━━━━━━━━━━━╺━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [32m2,021/20,000 [39m [ [33m0:01:02[39m < [36m0:10:17[39m , [31m29 it/s[39m ]
[35m  10%[39m [38m━━━━━━━━━━━━━━━━━━╸━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [32m2,069/20,000 [39m [ [33m0:01:03[39m < [36m0:10:10[39m , [31m29 it/s[39m ]
[35m  11%[39m [38m━━━━━━━━━━━━━━━━━━━╺━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [32m2,130/20,000 [39m [ [33m0:01:06[39m < [36m0:10:14[39m , [31m29 it/s[39m ]
[35m  11%[39m [38m━━━━━━━━━━━━━━━━━━━╸━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [32m2,194/20,000 [39m [ [33m0:01:08[39m < [36m0:10:14[39m , [31m29 it/s[39m ]
|    ent_coef_loss   | -7.07    |reward=3.30 +/- 6.18
|    ent_coef_loss   | -7.07    |reward=3.30 +/- 6.18
|    ent_coef_loss   | -7.07    |reward=3.30 +/- 6.18
[35m  12%[39m [38m━━━━━━━━━━━━━━━━━━━━━╸━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [32m2,402/20,000 [39m [ [33m0:01:16[39m < [36m0:10:49[39m , [31m27 it/s[39m ]
[35m  12%[39m [38m━━━━━━━━━━━━━━━━━━━━━━╺━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [32m2,472/20,000 [39m [ [33m0:01:18[39m < [36m0:10:38[39m , [31m27 it/s[39m ]
[35m  13%[39m [38m━━━━━━━━━━━━━━━━━━━━━━╸━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [32m2,534/20,000 [39m [ [33m0:01:20[39m < [36m0:10:41[39m , [31m27 it/s[39m ]
[35m  13%[39m [38m━━━━━━━━━━━━━━━━━━━━━━━╺━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [32m2,587/20,000 [39m [ [33m0:01:22[39m < [36m0:10:53[39m , [31m27 it/s[39m ]
|    ent_coef_loss   | -8.38    |reward=6.17 +/- 5.40
|    ent_coef_loss   | -8.38    |reward=6.17 +/- 5.40
|    ent_coef_loss   | -8.38    |reward=6.17 +/- 5.40
|    n_updates       | 2699     |
|    n_updates       | 2699     |
|    n_updates       | 2699     |
|    n_updates       | 2699     |