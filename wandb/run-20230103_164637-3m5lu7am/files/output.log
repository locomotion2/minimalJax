Loading hyperparameters from: .\hyperparams\tqc.yml
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('env_wrapper', 'stable_baselines3.common.monitor.Monitor'),
             ('learning_rate', 0.001),
             ('n_timesteps', 2000),
             ('policy', 'MlpPolicy')])
Using 1 environments
Creating test environment
Using cpu device
Log path: logs/tqc/TestEnvironment-v1_28
Logging to runs/TestEnvironment-v1__tqc__1414604070__1672760795\TestEnvironment-v1\TQC_1
Eval num_timesteps=200, episode_reward=8.16 +/- 6.98
Episode length: 200.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 200      |
|    mean_reward     | 8.16     |
| time/              |          |
|    total_timesteps | 200      |
| train/             |          |
|    actor_loss      | -2.81    |
|    critic_loss     | 0.00616  |
|    ent_coef        | 0.907    |
|    ent_coef_loss   | -0.33    |
|    learning_rate   | 0.001    |
|    n_updates       | 99       |
---------------------------------
New best mean reward!


Eval num_timesteps=400, episode_reward=11.68 +/- 6.80
Episode length: 200.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 200      |
|    mean_reward     | 11.7     |
| time/              |          |
|    total_timesteps | 400      |
| train/             |          |
|    actor_loss      | -3.19    |
|    critic_loss     | 0.00886  |
|    ent_coef        | 0.742    |
|    ent_coef_loss   | -1.01    |
|    learning_rate   | 0.001    |
|    n_updates       | 299      |
---------------------------------
New best mean reward!


Eval num_timesteps=600, episode_reward=7.09 +/- 6.21
Episode length: 200.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 200      |
|    mean_reward     | 7.09     |
| time/              |          |
|    total_timesteps | 600      |
| train/             |          |
|    actor_loss      | -3.59    |
|    critic_loss     | 0.00785  |
|    ent_coef        | 0.608    |
|    ent_coef_loss   | -1.68    |
|    learning_rate   | 0.001    |
|    n_updates       | 499      |
---------------------------------



Eval num_timesteps=800, episode_reward=6.90 +/- 7.19
Episode length: 200.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 200      |
|    mean_reward     | 6.9      |
| time/              |          |
|    total_timesteps | 800      |
| train/             |          |
|    actor_loss      | -3.91    |
|    critic_loss     | 0.00553  |
|    ent_coef        | 0.497    |
|    ent_coef_loss   | -2.35    |
|    learning_rate   | 0.001    |
|    n_updates       | 699      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 200      |
|    ep_rew_mean     | 0.666    |
| time/              |          |
|    episodes        | 4        |
|    fps             | 34       |
|    time_elapsed    | 23       |
|    total_timesteps | 800      |
---------------------------------


Eval num_timesteps=1000, episode_reward=2.82 +/- 2.15
Episode length: 200.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 200      |
|    mean_reward     | 2.82     |
| time/              |          |
|    total_timesteps | 1000     |
| train/             |          |
|    actor_loss      | -4.17    |
|    critic_loss     | 0.00565  |
|    ent_coef        | 0.407    |
|    ent_coef_loss   | -3.04    |
|    learning_rate   | 0.001    |
|    n_updates       | 899      |
---------------------------------
[35m  53%[39m [38m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [32m1,064/2,000 [39m [ [33m0:00:31[39m < [36m0:00:31[39m , [31m30 it/s[39m ]
[35m  57%[39m [38m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [32m1,132/2,000 [39m [ [33m0:00:33[39m < [36m0:00:29[39m , [31m30 it/s[39m ]
[35m  60%[39m [38m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [32m1,200/2,000 [39m [ [33m0:00:35[39m < [36m0:00:27[39m , [31m30 it/s[39m ]
[35m  63%[39m [38m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [32m1,252/2,000 [39m [ [33m0:00:38[39m < [36m0:00:26[39m , [31m29 it/s[39m ]
|    learning_rate   | 0.001    |
|    n_updates       | 1099     |
---------------------------------
[35m  66%[39m [38m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [32m1,320/2,000 [39m [ [33m0:00:40[39m < [36m0:00:23[39m , [31m30 it/s[39m ]
[35m  69%[39m [38m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [32m1,382/2,000 [39m [ [33m0:00:42[39m < [36m0:00:22[39m , [31m29 it/s[39m ]
|    ent_coef_loss   | -4.38    |reward=11.06 +/- 5.40
|    actor_loss      | -4.59    |
|    critic_loss     | 0.00613  |
|    ent_coef        | 0.273    |
|    ent_coef_loss   | -4.38    |reward=11.06 +/- 5.40
|    learning_rate   | 0.001    |
|    n_updates       | 1299     |
---------------------------------
[35m  75%[39m [38m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [32m1,502/2,000 [39m [ [33m0:00:46[39m < [36m0:00:18[39m , [31m29 it/s[39m ]
[35m  78%[39m [38m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [32m1,559/2,000 [39m [ [33m0:00:48[39m < [36m0:00:16[39m , [31m29 it/s[39m ]
|    total_timesteps | 1600     |
| rollout/           |          |
|    ep_len_mean     | 200      |
|    ep_rew_mean     | 4.7      |
| time/              |          |
|    episodes        | 8        |
|    fps             | 32       |
|    time_elapsed    | 49       |
|    total_timesteps | 1600     |
---------------------------------
[35m  84%[39m [38m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [32m1,678/2,000 [39m [ [33m0:00:52[39m < [36m0:00:11[39m , [31m30 it/s[39m ]
[35m  87%[39m [38m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━━━━━━━━━━━━━━━━━━━━━━[39m [32m1,746/2,000 [39m [ [33m0:00:54[39m < [36m0:00:09[39m , [31m30 it/s[39m ]
[35m  90%[39m [38m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━━━━━━━━━━━━━━━━━[39m [32m1,798/2,000 [39m [ [33m0:00:56[39m < [36m0:00:07[39m , [31m30 it/s[39m ]
|    critic_loss     | 0.00373  |reward=1.69 +/- 2.58
|    critic_loss     | 0.00373  |reward=1.69 +/- 2.58
|    critic_loss     | 0.00373  |reward=1.69 +/- 2.58
|    n_updates       | 1899     |reward=1.69 +/- 2.58
|    n_updates       | 1899     |reward=1.69 +/- 2.58